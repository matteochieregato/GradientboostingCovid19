{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier,Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Boruta_Shap import BorutaShap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA PREPARATION and PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From now on, suppose you have already a train-validation-test split of the data. Image features have been already extracted and joined to clinical features in respective data files. Minmax 0-1 normalization and zero-mean on image features has been already effected. Data files are .csv. Files contain also a binary 'OUTCOME' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenametrain='train_tenth_fold.csv'\n",
    "filenamevalid = 'valid_tenth_fold.csv'\n",
    "filenametest= 'test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain = pd.read_csv(filenametrain, header = 0, names=columns_eng)\n",
    "dfvalid = pd.read_csv(filenamevalid, header = 0, names=columns_eng)\n",
    "dftest = pd.read_csv(filenametest, header = 0, names=columns_eng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read  csv files as dataframes with pandas. Check colums in one of the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check outcome stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain['OUTCOME'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfvalid['OUTCOME'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest['OUTCOME'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set index on patient ID and extract outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain = dftrain.set_index('patient_id')\n",
    "dfvalid = dfvalid.set_index('patient_id')\n",
    "dftest = dftest.set_index('patient_id'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = dftrain.pop('OUTCOME').values\n",
    "y_valid = dfvalid.pop('OUTCOME').values\n",
    "y_test = dftest.pop('OUTCOME').values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "separate image features (40, in our case), for PCA.\n",
    "5 PCA are extracted on the training set.\n",
    "The PCA transform obtained in this way is applied also to the validation set and to the training set.\n",
    "The resulting features are then attached again to their respective instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcp=dftrain[['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31','32','33','34','35','36','37','38','39','40']]\n",
    "dfcpv=dfvalid[['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31','32','33','34','35','36','37','38','39','40']]\n",
    "dfcpt=dftest[['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31','32','33','34','35','36','37','38','39','40']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=5,svd_solver='full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "full solver is utilized to assure perfect reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(dfcp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpca=pd.DataFrame(pca.transform(dfcp), index=dfcp.index)\n",
    "dfpcav=pd.DataFrame(pca.transform(dfcpv), index=dfcpv.index)\n",
    "dfpcat=pd.DataFrame(pca.transform(dfcpt), index=dfcpt.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpca.columns = ['Feature_CT_1','Feature_CT_2','Feature_CT_3','Feature_CT_4','Feature_CT_5']\n",
    "dfpcav.columns = ['Feature_CT_1','Feature_CT_2','Feature_CT_3','Feature_CT_4','Feature_CT_5']\n",
    "dfpcat.columns = ['Feature_CT_1','Feature_CT_2','Feature_CT_3','Feature_CT_4','Feature_CT_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain=dftrain.drop(columns=['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31','32','33','34','35','36','37','38','39','40'])\n",
    "dfvalid=dfvalid.drop(columns=['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31','32','33','34','35','36','37','38','39','40'])\n",
    "dftest=dftest.drop(columns=['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31','32','33','34','35','36','37','38','39','40'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain=pd.merge(dftrain, dfpca, on='patient_ID', how='inner')\n",
    "dfvalid=pd.merge(dfvalid, dfpcav, on='patient_ID', how='inner')\n",
    "dftest=pd.merge(dftest, dfpcat, on='patient_ID', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in order to avoid compatibility problems, replace NaN with np.NaN and convert dtypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.replace('NaN',np.NaN,inplace=True)\n",
    "X_valid.replace('NaN',np.NaN,inplace=True)\n",
    "X_test.replace('NaN',np.NaN,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.convert_dtypes()\n",
    "X_valid = X_valid.convert_dtypes()\n",
    "X_test = X_test.convert_dtypes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "END of DATA PREPARATION and PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start building a preliminary CatBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run a dummy classifier on the training set to evaluate the learning rate. We fixed iterations at 700 in this phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbmodel = CatBoostClassifier(iterations=700, verbose=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split 0.8:0.2 the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "median imputation avoiding knowledge leakage, therefore keeping separate training and validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_imputer=SimpleImputer(missing_values=np.NaN,strategy='median')\n",
    "imputer=median_imputer.fit(train_X)\n",
    "v_train_X=imputer.transform(train_X)\n",
    "imputerval=median_imputer.fit(val_X)\n",
    "v_val_X=imputerval.transform(val_X)\n",
    "train_X=pd.DataFrame(v_train_X, columns=train_X.columns,index=train_X.index)\n",
    "val_X=pd.DataFrame(v_val_X, columns=val_X.columns,index=val_X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbdummy=cbmodel.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictdummy=cbdummy.get_all_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=dictdummy['learning_rate']*2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we doubled the CatBoost calculated learning rate for speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preliminary CatBoost classifier: Bayesian hyperparameter optimization with Optuna.\n",
    "All is done in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_auc=[]\n",
    "cb_param=[]\n",
    "\n",
    "def objective(trial):\n",
    "    train_X, val_X, train_y, val_y = train_test_split(X_train, y_train, test_size=0.2)\n",
    "    #again 0.8:0.2 inner split of the training set\n",
    "    \n",
    "    median_imputer=SimpleImputer(missing_values=np.NaN,strategy='median')\n",
    "    imputer=median_imputer.fit(train_X)\n",
    "    v_train_X=imputer.transform(train_X)\n",
    "    imputerval=median_imputer.fit(val_X)\n",
    "    v_val_X=imputerval.transform(val_X)\n",
    "    train_X=pd.DataFrame(v_train_X, columns=train_X.columns,index=train_X.index)\n",
    "    val_X=pd.DataFrame(v_val_X, columns=val_X.columns,index=val_X.index)\n",
    "    #again median imputation procedure\n",
    "    \n",
    "    param={\n",
    "        'verbose':1000,\n",
    "        'eval_metric':'AUC',\n",
    "        'depth' : trial.suggest_int('depth', 4, 10),\n",
    "        'objective' : trial.suggest_categorical('objective', ['Logloss', 'CrossEntropy']),\n",
    "        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.01, 0.1),\n",
    "        'l2_leaf_reg':trial.suggest_loguniform('l2_leaf_reg', 3, 30),\n",
    "        'boosting_type':'Ordered',\n",
    "        'bootstrap_type':'Bayesian',\n",
    "        'bagging_temperature' : trial.suggest_uniform('bagging_temperature', 0, 4),\n",
    "        'eta':lr,\n",
    "        'iterations':700,\n",
    "    }\n",
    "    if param['objective'] == 'Logloss':\n",
    "        param['random_strength'] = trial.suggest_uniform('random_strength', 0.5, 5)\n",
    "    #hyperparameter optimization list.\n",
    "    #The obiective is varied only to obtain a binary choice between fixed and optimizable random_strength.\n",
    "    \n",
    "    cbmodel = CatBoostClassifier(**param)\n",
    "                                                                                                 \n",
    "    cbmodel.fit(train_X, train_y)\n",
    "    predictioncb = cbmodel.predict_proba(val_X)\n",
    "    auccb = roc_auc_score(val_y, cbmodel.predict_proba(val_X) [:,1])\n",
    "    \n",
    "    roc_auc_score(val_y, cbmodel.predict_proba(val_X) [:,1])\n",
    "        \n",
    "    return auccb\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=300)\n",
    "    print(study.best_trial)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now pick the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_cb_preliminary=study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_cb_preliminary['verbose'] = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_preliminary = CatBoostClassifier(**params_cb_preliminary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start BorutaSHAP feature selection procedure, with the optimized CatBoost preliminary model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the BorutaSHAP procedure can be exceedingly long. Some suggestion to shorten it:\n",
    "\n",
    "reduce number of trials. 800 is a very high number. You can use TentativeRoughFix if uncertain features trouble you.\n",
    "\n",
    "you could change the voting from 6 over 8 to 5 over 5 or 4 over 5 or whatever. It depends from your dataset and the Shapley value distribution of it.\n",
    "\n",
    "you could optimize the preliminary mode on a different hyperparameter space. For example, you could restrict the number of leaves to 4-6.\n",
    "\n",
    "In any case, you should check for consistency of conserved/eliminated features between different training/validation folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optimiz_cb= cb_preliminary\n",
    "\n",
    "def cb_boruta(optimizer):\n",
    "    featurelist=[]\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=8, shuffle=True)\n",
    "    #Eight stratified split of the training set\n",
    "\n",
    "    for train_index, test_index in cv.split(X_train,y_train):\n",
    "\n",
    "        trainX = X_train.iloc[lambda x: train_index]\n",
    "        testX = X_train.iloc[lambda x: test_index]\n",
    "        trainy = np.take(y_train, train_index)\n",
    "        testy = np.take(y_train, test_index)\n",
    "        \n",
    "        median_imputer = SimpleImputer(missing_values = np.NaN,strategy = 'median')\n",
    "        imputer = median_imputer.fit(trainX)\n",
    "        vtrainX = imputer.transform(trainX)\n",
    "        imputertest = median_imputer.fit(testX)\n",
    "        vtestX = imputertest.transform(testX)\n",
    "        trainX = pd.DataFrame(vtrainX, columns = trainX.columns,index = trainX.index)\n",
    "        testX = pd.DataFrame(vtestX, columns = testX.columns,index = testX.index)\n",
    "        \n",
    "        #for each fold apply the post-split median imputation procedure\n",
    "        \n",
    "        Feature_Selector = BorutaShap(model = optimizer,\n",
    "                                  importance_measure = 'shap',\n",
    "                                  percentile = 85, \n",
    "                                  pvalue = 0.1,\n",
    "                                  classification = True)\n",
    "        \n",
    "        #weak BorutaShap feature selector. \n",
    "        #Percentile is lowered, pvalue is doubled, in respect to default.\n",
    "        \n",
    "        Feature_Selector.fit(trainX, trainy, n_trials=800, random_state=0)\n",
    "        #Feature_Selector.TentativeRoughFix()\n",
    "        #Uncomment the line above if you want no uncertain feature.\n",
    "        Feature_Selector.plot(X_size=12, figsize=(16,12),\n",
    "                y_scale='log', which_features='all')\n",
    "        #For the paper we plotted only the selected features.\n",
    "        \n",
    "        strainX = Feature_Selector.Subset()\n",
    "        selected = [x for x in strainX.columns]\n",
    "        print('features selected',selected)\n",
    "        rejected=Feature_Selector.rejected\n",
    "        featurelist.extend(rejected)\n",
    "        stestX = testX[selected]\n",
    "        optimizer.fit(strainX,trainy)\n",
    "        \n",
    "        rocboruta=roc_auc_score(testy, optimizer.predict_proba(stestX)[:,1])\n",
    "        \n",
    "        print(rocrocboruta)\n",
    "        \n",
    "    return featurelist\n",
    "      \n",
    "featsel=cb_boruta(optimiz_cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use a voting procedure to eliminate the features eliminated in six folds over eight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminated features for each fold are appended in the list featsel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feadrop=[feature for feature in featsel if featsel.count(feature)>=6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feadrop=list(set(feadrop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feadrop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop eliminated features from the training/validation/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainshort=X_train.drop(feadrop, axis=1)\n",
    "X_valshort=X_valid.drop(feadrop, axis=1)\n",
    "X_testshort=X_test.drop(feadrop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "END OF FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CATBOOST MODEL ON REDUCED FEATURE SPACE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there any feature that could be worthy of a finer quantization in CatBoost (Golden feature)?\n",
    "For example, in our model we tried both the first CT extracted feature and the PO2/FiO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gf1=X_trainshort.columns.get_loc(\"PaO2/FiO2\")\n",
    "gf2=X_trainshort.columns.get_loc(\"Feature_CT_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create the categorical options for quantization of golden features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1=str(gf1)+':border 1024'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2=str(gf2)+':border 1024'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3=str(gf1)+':border 254'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s4=[s1,s2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...back to the original CatBoost selected learning rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=lr/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optuna CatBoost hyperparameter optimization on reduced feature space. Again, in the training set.\n",
    "The goal is to create a shortlist of hyperparameter configurations to be checked on the validation set with the overfitting detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same as optuna hyperparameter optimization above\n",
    "\n",
    "cb_auc=[]\n",
    "cb_param=[]\n",
    "\n",
    "def objective(trial):\n",
    "    train_X, val_X, train_y, val_y = train_test_split(X_trainshort, y_train, test_size=0.2)\n",
    "    #again 0.8:0.2 inner split of the training set\n",
    "    median_imputer=SimpleImputer(missing_values=np.NaN,strategy='median')\n",
    "    imputer=median_imputer.fit(train_X)\n",
    "    v_train_X=imputer.transform(train_X)\n",
    "    imputerval=median_imputer.fit(val_X)\n",
    "    v_val_X=imputerval.transform(val_X)\n",
    "    train_X=pd.DataFrame(v_train_X, columns=train_X.columns,index=train_X.index)\n",
    "    val_X=pd.DataFrame(v_val_X, columns=val_X.columns,index=val_X.index)\n",
    "    #usual median imputation procedure \n",
    "    \n",
    "    \n",
    "    param={\n",
    "        'verbose':1000,\n",
    "        'eval_metric':'AUC',\n",
    "        'depth' : trial.suggest_int('depth', 4, 10),\n",
    "        'objective' : trial.suggest_categorical('objective', ['Logloss', 'CrossEntropy']),\n",
    "        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.01, 0.1),\n",
    "        'l2_leaf_reg':trial.suggest_loguniform('l2_leaf_reg', 3, 50),\n",
    "        'boosting_type':'Ordered',\n",
    "        'bootstrap_type': 'Bayesian',\n",
    "        'per_float_feature_quantization':trial.suggest_categorical('per_float_feature_quantization', ['13:border_count=1024','18:border_count=1024','18:border_count=254',['13:border_count=1024', '18:border_count=1024']]),                                           \n",
    "        'eta':lr,\n",
    "        'iterations':700,\n",
    "        'bagging_temperature': trial.suggest_uniform('bagging_temperature', 0, 4)\n",
    "    }\n",
    "    #it seems that you need to specify categorical suggestions actually writing them,\n",
    "    #e.g. copying s1, s2, s3, s4 as '13:border_count=1024','18:border_count=1024','18:border_count=254',['13:border_count=1024', '18:border_count=1024']\n",
    "    \n",
    "    if param['objective'] == 'Logloss':\n",
    "        param['random_strength'] = trial.suggest_uniform('random_strength', 0.5, 5)\n",
    "\n",
    "    cbmodel = CatBoostClassifier(**param)\n",
    "                                                 \n",
    "                                                    \n",
    "    cbmodel.fit(train_X, train_y)\n",
    "    predictioncb = cbmodel.predict_proba(val_X)\n",
    "    auccb = roc_auc_score(val_y, cbmodel.predict_proba(val_X) [:,1])\n",
    "    \n",
    "    \n",
    "    return auccb\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=300)\n",
    "    print(study.best_trial)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "put models in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs=study.trials_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shortlist models picking only AUC larger than a threshold value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alternative: pick the best ten models.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortlist=dfs.loc[dfs['value'] >= 0.96]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortlength=len(shortlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define the hyperparameters needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers=[x for x in shortlist['number']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictparam={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in numbers:\n",
    "    dictparam[x]={'verbose':1000,'depth' : shortlist.loc[x,'params_depth'],\n",
    "        'objective' : shortlist.loc[x,'params_objective'],\n",
    "        'colsample_bylevel': shortlist.loc[x,'params_colsample_bylevel'],\n",
    "        'l2_leaf_reg':shortlist.loc[x,'params_l2_leaf_reg'],\n",
    "        'boosting_type':'Ordered',\n",
    "        'bootstrap_type': 'Bayesian',\n",
    "        'per_float_feature_quantization':shortlist.loc[x,'params_per_float_feature_quantization'],                                           \n",
    "        'eta':0.008,\n",
    "        'iterations':20000,\n",
    "        'bagging_temperature': shortlist.loc[x,'params_bagging_temperature'],\n",
    "        'random_strength': shortlist.loc[x,'params_random_strength']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning rate fixed to a number slightly lower than the lr precedently used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "number of iterations fixed to a large number so to use overfitting detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean from nan (possible for random_strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_param = {k: {a: b for a, b in v.items() if not b!=b} for k, v in dictparam.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_optimized = [CatBoostClassifier(**clean_param[x]) for x in numbers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "usual median imputing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_imputer=SimpleImputer(missing_values=np.NaN,strategy='median')\n",
    "imputer=median_imputer.fit(X_trainshort)\n",
    "vXtrainshort=imputer.transform(X_trainshort)\n",
    "Xmtrain=pd.DataFrame(vXtrainshort, columns=X_trainshort.columns,index=X_trainshort.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_imputer = SimpleImputer(missing_values=np.NaN,strategy='median')\n",
    "imputer = median_imputer.fit(X_valshort)\n",
    "vXvalshort = imputer.transform(X_valshort)\n",
    "Xmvalid=pd.DataFrame(vXvalshort, columns=X_valshort.columns,index=X_valshort.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use Pool to select best iteration number with overfitting detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = Pool(data=Xmvalid,\n",
    "                    label=y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit shortlisted models to validation set, using overfitting detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itercb=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auccb=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(shortlength):\n",
    "    cb_optimized[i].fit(Xmtrain, y_train,eval_set=eval_dataset,use_best_model=True)\n",
    "    itera=cb_optimized[i].get_best_iteration()\n",
    "    score = roc_auc_score(y_valid, cb_optimized[i].predict_proba(Xmvalid) [:,1])\n",
    "    itercb.append(itera)\n",
    "    auccb.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_valid_auc=max(auccb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_valid_index = auccb.index(best_valid_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_valid_itera = itercb[best_valid_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_param=cb_optimized[best_valid_index].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_param['iterations']=best_valid_itera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "auc, best iteration number and parameters of the best model on validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "END OF CATBOOST MODEL ON REDUCED FEATURE SPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RETRAINING AND TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if the best validation model is indeed the best of all folds, retrain on joined training +validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then evaluate on the test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create the joined training+validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xshorttrainval=pd.concat([X_trainshort, X_valshort], axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yvaltrain=np.concatenate((y_train,y_valid),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do again the median imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_imputer = SimpleImputer(missing_values=np.NaN,strategy='median')\n",
    "imputer = median_imputer.fit(Xshorttrainval)\n",
    "vXtrainvalshort = imputer.transform(Xshorttrainval)\n",
    "Xmtrainval=pd.DataFrame(vXtrainvalshort, columns=Xshorttrainval.columns,index=Xshorttrainval.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_imputer = SimpleImputer(missing_values=np.NaN,strategy='median')\n",
    "imputer = median_imputer.fit(X_testshort)\n",
    "vXtestshort = imputer.transform(X_testshort)\n",
    "Xmtest=pd.DataFrame(vXtestshort, columns=X_testshort.columns,index=X_testshort.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since the train+validation set is larger, use 120% of the number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_param=best_val_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_param['iterations']=int(final_param['iterations']*1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_final=CatBoostClassifier(**final_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train it on the joined set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbfinal.fit(Xmtrainval, yvaltrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluate it on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aucfinal = roc_auc_score(y_test, cb_final.predict_proba(Xmtest) [:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do some plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cb_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(Xmtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHAP force plot for patient 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 6\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value, shap_values[i,:], Xmtest.iloc[i,:], link=\"logit\", show=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
